{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c7aa570-d091-413f-a75e-11658fb4b985",
   "metadata": {},
   "source": [
    "### Imports and why we need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59646a24-4490-4727-840f-b25df94d7596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dac8308-f2b8-4fa5-8a1d-ad05c801ed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Code block to visualise raw data\n",
    "diabetes_visual = pd.read_csv(\"diabetes.csv\")\n",
    "diabetes_visual.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49cf242-919a-49c5-823a-a513cc7ae8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_visual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a86e5-769a-4471-b66c-3abfb7959d77",
   "metadata": {},
   "source": [
    "### Visualis the data using scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261dfa7-4235-445d-8f01-144a469a5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(diabetes_visual, hue='Outcome', vars=diabetes_visual.columns[:-1],height=2.5, aspect=2.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ddf2bd-6edf-4bc1-9f07-8a5cdf26345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(diabetes_visual.columns) - 1, figsize=(20, 2.5), sharey=True)\n",
    "\n",
    "# Loop through each feature and create a scatter plot vs Outcome\n",
    "for i, feature in enumerate(diabetes_visual.columns[:-1]):\n",
    "    sns.scatterplot(x=diabetes_visual[feature], y=diabetes_visual['Outcome'], ax=axes[i])\n",
    "    axes[i].set_title(f'{feature} vs Outcome')\n",
    "    axes[i].set_xlabel(feature)\n",
    "\n",
    "# Set common y label\n",
    "axes[0].set_ylabel('Outcome')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d076d2d-88a0-4b1b-9ed2-ef4ff81d163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = diabetes_visual.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c6934-88bb-4228-b415-e825ce6e1c2e",
   "metadata": {},
   "source": [
    "### Attempt to data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38364b52-9600-4a50-ac7b-8cb32dc8f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_visual.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a57c33-f0cc-4add-9565-d528ae4d03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(diabetes_visual == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a44c6-f6c1-49e6-a212-fc00ce725c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "(diabetes_visual == 0).mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b25c6-4f93-4b39-9d2d-d5533341b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to check for na value and print\n",
    "url_data_from_website = \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binar/diabetes\"\n",
    "local_file_data_from_website = \"diabetes.txt\"\n",
    "\n",
    "try:\n",
    "    # Attempt to fetch the data from the URL\n",
    "    response_data_from_website = requests.get(url_data_from_website)\n",
    "    response_data_from_website.raise_for_status()  # Raise an error if the request failed\n",
    "\n",
    "    # Load data from the fetched content\n",
    "    data_data_from_website = BytesIO(response_data_from_website.content)\n",
    "    X_data_from_website, y_data_from_website = load_svmlight_file(data_data_from_website)\n",
    "    print(\"Data loaded from URL.\")\n",
    "\n",
    "except (requests.exceptions.RequestException, IOError):\n",
    "    # If the URL fetch fails, fall back to the local file\n",
    "    if os.path.exists(local_file_data_from_website):\n",
    "        with open(local_file_data_from_website, 'rb') as file:\n",
    "            X_data_from_websitee, y_data_from_website = load_svmlight_file(file)\n",
    "        print(\"Data loaded from local file.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Both URL and local file '{local_file}' are unavailable.\")\n",
    "\n",
    "diabetes_data_from_website = pd.DataFrame(X_data_from_websitee.toarray())\n",
    "diabetes_data_from_website['outcome'] = y_data_from_website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bcbf85-b788-4960-b17c-084df8508a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data_from_website.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a7d91-b803-422b-ae1e-5775b984e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Are these column 0 (Pregnancies) value same :\",(diabetes_visual.iloc[:, 0].values == diabetes_data_from_website.iloc[:, 0].values).all())\n",
    "print(\"Are these column 1 (Glucose) value same :\",(diabetes_visual.iloc[:, 1].values == diabetes_data_from_website.iloc[:, 1].values).all())\n",
    "print(\"Are these column 2 (BloodPressure) value same :\",(diabetes_visual.iloc[:, 2].values == diabetes_data_from_website.iloc[:, 2].values).all())\n",
    "print(\"Are these column 3 (SkinThickness) value same :\",(diabetes_visual.iloc[:, 3].values == diabetes_data_from_website.iloc[:, 3].values).all())\n",
    "print(\"Are these column 4 (Insulin) value same :\",(diabetes_visual.iloc[:, 4].values == diabetes_data_from_website.iloc[:, 4].values).all())\n",
    "print(\"Are these column 5 (BMI) value same :\",(diabetes_visual.iloc[:, 5].round(1).values == diabetes_data_from_website.iloc[:, 5].round(1).values).all())\n",
    "print(\"Are these column 6 (DiabetesPedigreeFunction) value same :\",(diabetes_visual.iloc[:, 6].values == diabetes_data_from_website.iloc[:, 6].values).all())\n",
    "print(\"Are these column 7 (Age) value same :\",(diabetes_visual.iloc[:, 7].values == diabetes_data_from_website.iloc[:, 7].values).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0784e7-78ed-4a44-a080-af5159d42d91",
   "metadata": {},
   "source": [
    "#### Since data are equal without any error value we can safely use the scaled data, in the later section we may see what happens if we use our won pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5fd06b-ffb6-4dd9-9aa7-446b981bb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_scale = \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binar/diabetes_scale\"\n",
    "local_file = \"diabetes_scale.txt\"\n",
    "\n",
    "try:\n",
    "    # Attempt to fetch the data from the URL\n",
    "    response_scale = requests.get(url_scale)\n",
    "    response_scale.raise_for_status()  # Raise an error if the request failed\n",
    "\n",
    "    # Load data from the fetched content\n",
    "    data_scale = BytesIO(response_scale.content)\n",
    "    X_scale, y_scale = load_svmlight_file(data_scale)\n",
    "    print(\"Data loaded from URL.\")\n",
    "\n",
    "except (requests.exceptions.RequestException, IOError):\n",
    "    # If the URL fetch fails, fall back to the local file\n",
    "    if os.path.exists(local_file):\n",
    "        with open(local_file, 'rb') as file:\n",
    "            X_scale, y_scale = load_svmlight_file(file)\n",
    "        print(\"Data loaded from local file.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Both URL and local file '{local_file}' are unavailable.\")\n",
    "\n",
    "# Create a DataFrame with the scaled data\n",
    "diabetes_data__scale = pd.DataFrame(X_scale.toarray())\n",
    "diabetes_data__scale['outcome'] = y_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ddcf3-8abe-462a-9516-0ba198e0a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled = diabetes_data__scale['outcome']\n",
    "X_scaled = diabetes_data__scale.drop('outcome', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8cf1f4-e9a0-4766-91bd-a0454de711e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae3205-8f69-451d-b802-5032380ce61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f61d9c-4f88-493d-a03f-2b1f2f8eef3d",
   "metadata": {},
   "source": [
    "### After decision is made to what to do with the data split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8c98a-ffbe-4a0c-8fab-2c5bf92b45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "X_scaled_numpy = X_scaled.to_numpy()\n",
    "y_scaled_numpy = y_scaled.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c02281c-e406-44f1-ad09-0ebc9b38eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into\n",
    "# Test Train Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_big_train, X_test, y_big_train, y_test = train_test_split(\n",
    "    X_scaled_numpy, y_scaled_numpy, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_big_train, y_big_train, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62b51d-6747-4d82-a2db-9f88db979a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)  # Training features\n",
    "print(\"X_val shape:\", X_val.shape)  # Validation features\n",
    "print(\"X_test shape:\", X_test.shape)              # Test features\n",
    "print(\"y_train shape:\", y_train.shape)    # Training targets\n",
    "print(\"y_val shape:\", y_val.shape)    # Training targets\n",
    "print(\"y_test shape:\", y_test.shape)               # Test targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93013f6a-28a7-41a8-b862-411abf94f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c3f3a-044e-4ee1-b161-4b6c363f548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to Tensors\n",
    "\n",
    "# Training Set\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Validation Set\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Test Set\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a8014-541a-419e-b105-aedeb892d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e594c8-adf6-435d-9e6f-b2ec540bb494",
   "metadata": {},
   "source": [
    "### Define the Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca6601-fc6a-4fa3-810a-0e92192a4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c26af9-0101-4218-af8a-961aa39ebaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron_Sign_Without_Bias(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Perceptron_Sign_Without_Bias, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, 1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sign(self.fc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7488b7f5-26c0-454a-ad39-7ea725ac688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron_Sign_With_Bias(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Perceptron_Sign_With_Bias, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sign(self.fc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ee493-927b-4ada-a154-b8793e1cbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76661c40-7cf5-448e-812e-2b19e9f75ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # Set the random seed for Python's random module\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Set the seed for NumPy\n",
    "    #np.random.seed(seed)\n",
    "    \n",
    "    # Set the seed for PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # If using CUDA, set the seed for CUDA as well\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "\n",
    "    # Set the deterministic flag for reproducibility (may impact performance)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadfb106-876d-4339-a2f4-259cede05f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(model, data, labels, val_data, val_labels, epochs, learning_rate):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_updates = 0\n",
    "        correct_predictions = 0  # Initialize correct predictions counter\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(data[i])\n",
    "            predicted_label = output.item()  # Get the predicted output\n",
    "            \n",
    "            # Check if the prediction is correct\n",
    "            if labels[i] * predicted_label <= 0:  # Misclassified\n",
    "                total_updates += 1\n",
    "                if labels[i] == 1:\n",
    "                    # Adjust weights for positive misclassification\n",
    "                    model.fc.weight.data += learning_rate * data[i]\n",
    "                else:\n",
    "                    # Adjust weights for negative misclassification\n",
    "                    model.fc.weight.data -= learning_rate * data[i]\n",
    "            else:\n",
    "                correct_predictions += 1  # Increment correct predictions\n",
    "            \n",
    "        # Calculate training accuracy for the epoch\n",
    "        train_accuracy = correct_predictions / len(data) * 100  # Convert to percentage\n",
    "        \n",
    "        # Calculate validation accuracy\n",
    "        val_correct_predictions = 0\n",
    "        with torch.no_grad():  \n",
    "            for j in range(len(val_data)):\n",
    "                val_output = model(val_data[j])\n",
    "                if val_labels[j] * val_output.item() > 0:  # Correctly classified\n",
    "                    val_correct_predictions += 1\n",
    "        \n",
    "        val_accuracy = val_correct_predictions / len(val_data) * 100  # Convert to percentage\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Training Accuracy: {train_accuracy:.2f}%, '\n",
    "              f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "        \n",
    "        # Check convergence\n",
    "        if total_updates == 0:\n",
    "            print(f'Converged after {epoch + 1} epochs.')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0615e641-4846-453e-813c-fbe9c7d47ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sign_Without_Bias(input_dim=8)\n",
    "train_perceptron(model, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, epochs=10, learning_rate=0.1)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "with torch.no_grad():\n",
    "    predictions_sign_without_bias_lr_0_1 = model(X_test_tensor)\n",
    "\n",
    "accuracy = accuracy_score(y_test_tensor.numpy(), predictions_sign_without_bias_lr_0_1.numpy())\n",
    "print(f'Test Accuracy Perceptron Sign Without Bias LR 0.1: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f478cfcf-1e74-4ce1-a1f4-e648216a7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387eaaf-3925-4cf0-8d23-ebd3c9da253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sign_With_Bias(input_dim=8)\n",
    "train_perceptron(model, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, epochs=10, learning_rate=0.1)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "with torch.no_grad():\n",
    "    predictions_sign_with_bias_lr_0_1 = model(X_test_tensor)\n",
    "\n",
    "accuracy = accuracy_score(y_test_tensor.numpy(), predictions_sign_with_bias_lr_0_1.numpy())\n",
    "print(f'Test Accuracy Perceptron Sign With Bias LR 0.1: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31086ae-c2f7-4084-84f2-c60b403b1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68d618-6847-4bee-8f9a-87c601b81c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sign_Without_Bias(input_dim=8)\n",
    "train_perceptron(model, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, epochs=10, learning_rate=0.01)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "with torch.no_grad():\n",
    "    predictions_sign_without_bias_lr_0_0_1 = model(X_test_tensor)\n",
    "\n",
    "accuracy = accuracy_score(y_test_tensor.numpy(), predictions_sign_without_bias_lr_0_0_1.numpy())\n",
    "print(f'Test Accuracy Perceptron Sigmoid Without Bias LR 0.01: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b934a-b44f-4d4c-bd7a-611a8e8081ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012e579-562e-46a9-a147-55c4f579ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sign_With_Bias(input_dim=8)\n",
    "train_perceptron(model, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, epochs=10, learning_rate=0.01)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "with torch.no_grad():\n",
    "    predictions_sign_with_bias_lr_0_0_1 = model(X_test_tensor)\n",
    "\n",
    "accuracy = accuracy_score(y_test_tensor.numpy(), predictions_sign_with_bias_lr_0_0_1.numpy())\n",
    "print(f'Test Accuracy Perceptron Sign With Bias  LR 0.01: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2053b384-ffbf-4f51-b4b3-fec6835abc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0c6ab-327e-4b18-afc5-38a6bc745567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "perceptron_sklearn = Perceptron(random_state=42, validation_fraction=0.2, early_stopping=True)\n",
    "perceptron_sklearn.fit(X_big_train, (y_big_train+1)/2)\n",
    "accuracy = perceptron_sklearn.score(X_test, (y_test+1)/2)\n",
    "print(f'Test Accuracy Sklearn Perceptron: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b5c41-d15a-40d3-90af-5e83ce2cb0c2",
   "metadata": {},
   "source": [
    "### Expreimentation with the perceptron\n",
    "- Sign activation function with bias\n",
    "- Try a different activation function (Sigmoid) and notice the perfromance\n",
    "- Try different learning rates on both the signmoid and sign activated\n",
    "- Select the best (which is obviously the sigmoid)\n",
    "- try backpropagatiob on each on the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75576ba4-784f-43e5-827c-aa3ca1da0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different activation function\n",
    "class Perceptron_Sigmoid(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Perceptron_Sigmoid, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc(x))\n",
    "\n",
    "\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    correct = (predictions == labels).float()\n",
    "    accuracy = correct.sum() / len(labels)\n",
    "    return accuracy\n",
    "\n",
    "def training_validation(model, X_train_tensor, y_train_tensor, X_val_tensor, \n",
    "                        y_val_tensor, batch_size, num_epochs, criterion, optimizer):\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "    \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_predictions = (val_outputs > 0.5).float()\n",
    "            val_accuracy = calculate_accuracy(val_predictions, y_val_tensor)\n",
    "            val_loss = criterion(val_outputs, y_val_tensor).item()\n",
    "            \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {epoch_loss:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, '\n",
    "          f'Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f5aa4a-dee5-4616-b1d0-362bcfe4792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = (y_train_tensor+1)/2\n",
    "y_val_tensor = (y_val_tensor+1)/2\n",
    "y_test_tensor = (y_test_tensor+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d967ed5-b1bf-4b85-8f7e-66bceff09c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, loss function, and optimizer\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Common\n",
    "input_size = 8\n",
    "seed = 42\n",
    "criterion = nn.BCELoss()\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "# Creating data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b1165-4a5a-44fb-abbc-ea032536108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Sigmoid With Bias SGD Optim LR 0.1\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sigmoid(input_size)\n",
    "optimizer_sgd_lr_0_1 = optim.SGD(model.parameters(), lr=0.1)\n",
    "training_validation(model, X_train_tensor, y_train_tensor, X_val_tensor, \n",
    "                        y_val_tensor, batch_size, num_epochs, criterion, optimizer_sgd_lr_0_1)\n",
    "with torch.no_grad():\n",
    "    outputs_sgd_lr_0_1 = model(X_test_tensor)\n",
    "    predicted_labels_sgd_lr_0_1 = (outputs_sgd_lr_0_1 >= 0.5).float()\n",
    "\n",
    "accuracy_sgd_lr_0_1 = accuracy_score(y_test_tensor.numpy(), predicted_labels_sgd_lr_0_1.numpy())\n",
    "print(f'\\n Test Accuracy Perceptron Sigmoid With Bias SGD Optim LR 0.1: {accuracy_sgd_lr_0_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a307ac-8527-4630-870c-8b14ab73f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd237a66-ed33-4450-92cb-6422cb5b196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Sigmoid With Bias SGD Optim LR 0.01\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sigmoid(input_size)\n",
    "optimizer_sgd_lr_0_0_1 = optim.SGD(model.parameters(), lr=0.01)\n",
    "training_validation(model, X_train_tensor, y_train_tensor, X_val_tensor, \n",
    "                        y_val_tensor, batch_size, num_epochs, criterion, optimizer_sgd_lr_0_0_1)\n",
    "with torch.no_grad():\n",
    "    outputs_sgd_lr_0_0_1 = model(X_test_tensor)\n",
    "    predicted_labels_sgd_lr_0_0_1 = (outputs_sgd_lr_0_0_1 >= 0.5).float()\n",
    "\n",
    "accuracy_sgd_lr_0_0_1 = accuracy_score(y_test_tensor.numpy(), predicted_labels_sgd_lr_0_0_1.numpy())\n",
    "print(f'\\n Test Accuracy Perceptron Sigmoid With Bias SGD Optim LR 0.01: {accuracy_sgd_lr_0_0_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc86e9-764c-4baa-9419-61f16b0b0207",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfbc5a7-7558-4e8e-9699-c300ddf5edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Sigmoid With Bias Adam Optim LR 0.1\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sigmoid(input_size)\n",
    "optimizer_adam_lr_0_1 = optim.Adam(model.parameters(), lr=0.1)\n",
    "training_validation(model, X_train_tensor, y_train_tensor, X_val_tensor, \n",
    "                        y_val_tensor, batch_size, num_epochs, criterion, optimizer_adam_lr_0_1)\n",
    "with torch.no_grad():\n",
    "    outputs_adam_lr_0_1 = model(X_test_tensor)\n",
    "    predicted_labels_adam_lr_0_1 = (outputs_adam_lr_0_1 >= 0.5).float()\n",
    "\n",
    "accuracy_adam_lr_0_1 = accuracy_score(y_test_tensor.numpy(), predicted_labels_adam_lr_0_1.numpy())\n",
    "print(f'\\n Test Accuracy Perceptron Sigmoid With Bias Adam Optim LR 0.1: {accuracy_adam_lr_0_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce17d6c-fb87-42a6-a695-4c0284af82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189753a2-af7e-48ba-8050-b2f3bc9d0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Sigmoid With Bias Adam Optim LR 0.01\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sigmoid(input_size)\n",
    "optimizer_adam_lr_0_0_1 = optim.Adam(model.parameters(), lr=0.01)\n",
    "training_validation(model, X_train_tensor, y_train_tensor, X_val_tensor, \n",
    "                        y_val_tensor, batch_size, num_epochs, criterion, optimizer_adam_lr_0_0_1)\n",
    "with torch.no_grad():\n",
    "    outputs_adam_lr_0_0_1 = model(X_test_tensor)\n",
    "    predicted_labels_adam_lr_0_0_1 = (outputs_adam_lr_0_0_1 >= 0.5).float()\n",
    "\n",
    "accuracy_adam_lr_0_0_1 = accuracy_score(y_test_tensor.numpy(), predicted_labels_adam_lr_0_0_1.numpy())\n",
    "print(f'\\n Test Accuracy Perceptron Sigmoid With Bias Adam Optim LR 0.01: {accuracy_adam_lr_0_0_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4437b2-36aa-42fa-897d-14956e60e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c2d27-cc38-4e19-b398-8d1e715d8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Sigmoid With Bias RMSprop Optim LR 0.1\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sigmoid(input_size)\n",
    "optimizer_rmsprop_lr_0_1 = optim.RMSprop(model.parameters(), lr=0.1)\n",
    "training_validation(model, X_train_tensor, y_train_tensor, X_val_tensor, \n",
    "                        y_val_tensor, batch_size, num_epochs, criterion, optimizer_rmsprop_lr_0_1)\n",
    "with torch.no_grad():\n",
    "    outputs_rmsprop_lr_0_1 = model(X_test_tensor)\n",
    "    predicted_labels_rmsprop_lr_0_1 = (outputs_rmsprop_lr_0_1 >= 0.5).float()\n",
    "\n",
    "accuracy_rmsprop_lr_0_1 = accuracy_score(y_test_tensor.numpy(), predicted_labels_rmsprop_lr_0_1.numpy())\n",
    "print(f'\\n Test Accuracy Perceptron Sigmoid With Bias RMSProp Optim LR 0.1: {accuracy_rmsprop_lr_0_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19dbc5-70df-4848-817d-926c3a0ce59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65adb9b-6b1c-4688-a020-d8b771a07f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Sigmoid With Bias RMSprop Optim LR 0.01\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sigmoid(input_size)\n",
    "optimizer_rmsprop_lr_0_0_1 = optim.RMSprop(model.parameters(), lr=0.01)\n",
    "training_validation(model, X_train_tensor, y_train_tensor, X_val_tensor, \n",
    "                        y_val_tensor, batch_size, num_epochs, criterion, optimizer_rmsprop_lr_0_0_1)\n",
    "with torch.no_grad():\n",
    "    outputs_rmsprop_lr_0_0_1 = model(X_test_tensor)\n",
    "    predicted_labels_rmsprop_lr_0_0_1 = (outputs_rmsprop_lr_0_0_1 >= 0.5).float()\n",
    "\n",
    "accuracy_rmsprop_lr_0_0_1 = accuracy_score(y_test_tensor.numpy(), predicted_labels_rmsprop_lr_0_0_1.numpy())\n",
    "print(f'\\n Test Accuracy Perceptron Sigmoid With Bias RMSProp Optim LR 0.01: {accuracy_rmsprop_lr_0_0_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48a0cd-ca84-42f2-84af-67bc9d3dcba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824e271-b19e-48fe-9aa1-d55ce9c2a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Sigmoid With Bias NAdam Optim LR 0.1\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sigmoid(input_size)\n",
    "optimizer_nadam_lr_0_1 = optim.NAdam(model.parameters(), lr=0.1)\n",
    "training_validation(model, X_train_tensor, y_train_tensor, X_val_tensor, \n",
    "                        y_val_tensor, batch_size, num_epochs, criterion, optimizer_nadam_lr_0_1)\n",
    "with torch.no_grad():\n",
    "    outputs_nadam_lr_0_1 = model(X_test_tensor)\n",
    "    predicted_labels_nadam_lr_0_1 = (outputs_nadam_lr_0_1 >= 0.5).float()\n",
    "\n",
    "accuracy_nadam_lr_0_1 = accuracy_score(y_test_tensor.numpy(), predicted_labels_nadam_lr_0_1.numpy())\n",
    "print(f'\\n Test Accuracy Perceptron Sigmoid With Bias Ndam Optim LR 0.1: {accuracy_nadam_lr_0_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6217eb91-8091-44d1-8957-6ba0dbeac99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a02aca-5f21-4714-b3fd-4eef7a274907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Sigmoid With Bias NAdam Optim LR 0.01\n",
    "set_seed(seed)\n",
    "model = Perceptron_Sigmoid(input_size)\n",
    "optimizer_nadam_lr_0_0_1 = optim.NAdam(model.parameters(), lr=0.01)\n",
    "training_validation(model, X_train_tensor, y_train_tensor, X_val_tensor, \n",
    "                        y_val_tensor, batch_size, num_epochs, criterion, optimizer_nadam_lr_0_0_1)\n",
    "with torch.no_grad():\n",
    "    outputs_nadam_lr_0_0_1 = model(X_test_tensor)\n",
    "    predicted_labels_nadam_lr_0_0_1 = (outputs_nadam_lr_0_0_1 >= 0.5).float()\n",
    "\n",
    "accuracy_nadam_lr_0_0_1 = accuracy_score(y_test_tensor.numpy(), predicted_labels_nadam_lr_0_0_1.numpy())\n",
    "print(f'\\n Test Accuracy Perceptron Sigmoid With Bias Ndam Optim LR 0.1: {accuracy_nadam_lr_0_0_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223bc99-635a-43fc-951a-1204dbbd3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db6dd4-4d66-4b54-a1f8-8560e0f0abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), random_state=42, learning_rate_init=0.01,validation_fraction=0.2, early_stopping=True)\n",
    "mlp.fit(X_big_train, (y_big_train.ravel()+1)/2)\n",
    "\n",
    "# Training accuracy\n",
    "train_accuracy = accuracy_score(y_train_tensor.numpy(), mlp.predict(X_train_tensor.numpy()))\n",
    "\n",
    "# Testing accuracy\n",
    "test_accuracy = accuracy_score(y_test_tensor.numpy(), mlp.predict(X_test_tensor.numpy()))\n",
    "\n",
    "print(f'MLP Training Accuracy: {train_accuracy:.3f}')\n",
    "print(f'MLP Testing Accuracy: {test_accuracy:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95cc3a0-2f41-4f74-a70c-87f7f2556018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP (300-100)\n",
    "mlp_300_100 = MLPClassifier(hidden_layer_sizes=(300, 100), random_state=42,learning_rate_init=0.01, validation_fraction=0.2, early_stopping=True)\n",
    "mlp_300_100.fit(X_big_train, (y_big_train.ravel()+1)/2)\n",
    "\n",
    "# Training accuracy\n",
    "train_accuracy_300_100 = accuracy_score(y_train_tensor.numpy(), mlp_300_100.predict(X_train_tensor.numpy()))\n",
    "\n",
    "# Testing accuracy\n",
    "test_accuracy_300_100 = accuracy_score(y_test_tensor.numpy(), mlp_300_100.predict(X_test_tensor.numpy()))\n",
    "\n",
    "print(f'MLP 300 100 Training Accuracy: {train_accuracy_300_100:.3f}')\n",
    "print(f'MLP 300 100 Testing Accuracy: {test_accuracy_300_100:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbf45e-e094-4465-9d64-6ad9f3c6acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC(max_iter=1000, random_state=42)\n",
    "svm_model.fit(X_train_tensor.numpy(), y_train_tensor.numpy().ravel())\n",
    "\n",
    "# Training accuracy\n",
    "train_accuracy_svm = accuracy_score(y_train_tensor.numpy(), svm_model.predict(X_train_tensor.numpy()))\n",
    "\n",
    "# Validation accuracy\n",
    "val_accuracy_svm = accuracy_score(y_val_tensor.numpy(), svm_model.predict(X_val_tensor.numpy()))\n",
    "\n",
    "# Testing accuracy\n",
    "test_accuracy_svm = accuracy_score(y_test_tensor.numpy(), svm_model.predict(X_test_tensor.numpy()))\n",
    "\n",
    "print(f'SVM Training Accuracy: {train_accuracy_svm:.3f}')\n",
    "print(f'SVM Validation Accuracy: {val_accuracy_svm:.3f}')\n",
    "print(f'SVM Testing Accuracy: {test_accuracy_svm:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b75678-ecb1-4001-ab47-5929b837b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create confusion matrices\n",
    "cm_1 = confusion_matrix(y_test, predictions_sign_without_bias_lr_0_1) # Perceptron Sign Without Bias LR 0.1\n",
    "cm_2 = confusion_matrix(y_test, predictions_sign_with_bias_lr_0_1) # Perceptron Sign With Bias LR 0.1\n",
    "cm_3 = confusion_matrix(y_test, predictions_sign_without_bias_lr_0_0_1) # Perceptron Sign Without Bias LR 0.01\n",
    "cm_4 = confusion_matrix(y_test, predictions_sign_with_bias_lr_0_0_1) # Perceptron Sign With Bias LR 0.01\n",
    "cm_5 = confusion_matrix((y_test+1)/2, perceptron_sklearn.predict(X_test)) # Perceptron sklearn\n",
    "cm_6 = confusion_matrix(y_test_tensor.numpy(), predicted_labels_sgd_lr_0_1.numpy())  # SGD Optim LR 0.1\n",
    "cm_7 = confusion_matrix(y_test_tensor.numpy(), predicted_labels_sgd_lr_0_0_1.numpy())  # SGD Optim LR 0.01\n",
    "cm_8 = confusion_matrix(y_test_tensor.numpy(), predicted_labels_adam_lr_0_1.numpy())  # Adam Optim LR 0.1\n",
    "cm_9 = confusion_matrix(y_test_tensor.numpy(), predicted_labels_adam_lr_0_0_1.numpy())  # Adam Optim LR 0.01\n",
    "cm_10 = confusion_matrix(y_test_tensor.numpy(), predicted_labels_rmsprop_lr_0_1.numpy())  # RMSprop Optim LR 0.1\n",
    "cm_11 = confusion_matrix(y_test_tensor.numpy(), predicted_labels_rmsprop_lr_0_0_1.numpy())  # RMSprop Optim LR 0.01\n",
    "cm_12 = confusion_matrix(y_test_tensor.numpy(), predicted_labels_nadam_lr_0_1.numpy())  # Nadam Optim LR 0.1\n",
    "cm_13 = confusion_matrix(y_test_tensor.numpy(), predicted_labels_nadam_lr_0_0_1.numpy())  # Nadam Optim LR 0.01\n",
    "\n",
    "# Create subplots with 3 rows and 3 columns\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 13))  # Adjust size as needed\n",
    "\n",
    "# List of confusion matrices and titles\n",
    "cms = [cm_1, cm_2, cm_3, cm_4, cm_5, cm_6, cm_7, cm_8, cm_9, cm_10, cm_11, cm_12, cm_13]\n",
    "titles = [\n",
    "    'CM Sign Without Bias LR 0.1',\n",
    "    'CM Sign With Bias LR 0.1',\n",
    "    'CM Sign Without Bias LR 0.01',\n",
    "    'CM Sign With Bias LR 0.01',\n",
    "    'CM Perceptron sklearn',\n",
    "    'CM SGD Optim LR 0.1',\n",
    "    'CM SGD Optim LR 0.01',\n",
    "    'CM Adam Optim LR 0.1',\n",
    "    'CM Adam Optim LR 0.01',\n",
    "    'CM RMSprop Optim LR 0.1',\n",
    "    'CM RMSprop Optim LR 0.01',\n",
    "    'CM Nadam Optim LR 0.1',\n",
    "    'CM Nadam Optim LR 0.01'\n",
    "]\n",
    "\n",
    "# Loop through the confusion matrices and their respective titles\n",
    "for i, (cm, title) in enumerate(zip(cms, titles)):\n",
    "    row, col = divmod(i, 4)  # Determine the row and column for the subplot\n",
    "    \n",
    "    # Change the labels only for cm_1 to cm_4 (indices 0 to 3)\n",
    "    if i < 4:\n",
    "        xticks = ['Predicted -1', 'Predicted 1']\n",
    "        yticks = ['Actual -1', 'Actual 1']\n",
    "    else:\n",
    "        xticks = ['Predicted 0', 'Predicted 1']\n",
    "        yticks = ['Actual 0', 'Actual 1']\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                ax=axes[row, col],\n",
    "                xticklabels=xticks,\n",
    "                yticklabels=yticks)\n",
    "\n",
    "    axes[row, col].set_xlabel('Predicted Labels')\n",
    "    axes[row, col].set_ylabel('True Labels')\n",
    "    axes[row, col].set_title(title)\n",
    "\n",
    "# Turn off the last unused axes\n",
    "total_plots = len(cms)\n",
    "for i in range(total_plots, len(axes.flat)):\n",
    "    axes.flat[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee533134-f927-49e8-a747-79b6f2552020",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_14 = confusion_matrix(y_test_tensor.numpy(), mlp.predict(X_test_tensor.numpy()))  # MLP default\n",
    "cm_15 = confusion_matrix(y_test_tensor.numpy(), mlp_300_100.predict(X_test_tensor.numpy()))  # Nadam Optim LR 0.01\n",
    "cm_16 = confusion_matrix(y_test_tensor.numpy(), svm_model.predict(X_test_tensor.numpy()))  # Nadam Optim LR 0.01\n",
    "\n",
    "# Create subplots with 3 rows and 3 columns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 6))  # Adjust size as needed\n",
    "\n",
    "# List of confusion matrices and titles\n",
    "cms = [cm_11, cm_14, cm_15, cm_16]\n",
    "titles = [\n",
    "    'CM RMSprop Optim LR 0.01',\n",
    "    'CM MLP Default',\n",
    "    'CM MLP 300 100',\n",
    "    'CM SVM'\n",
    "]\n",
    "\n",
    "# Loop through the confusion matrices and their respective titles\n",
    "for i, (cm, title) in enumerate(zip(cms, titles)):\n",
    "    row, col = divmod(i, 2)  # Determine the row and column for the subplot\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                ax=axes[row, col],\n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "\n",
    "    axes[row, col].set_xlabel('Predicted Labels')\n",
    "    axes[row, col].set_ylabel('True Labels')\n",
    "    axes[row, col].set_title(title)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be7f28-912e-43d3-a77b-256a00760aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "print(f'Precision Sign without bias LR 0.1 : {precision_score(y_test,predictions_sign_without_bias_lr_0_1):.3f}') # Perceptron Sign Without Bias LR 0.1\n",
    "print(f'Precision Sign without bias LR 0.1 : {precision_score(y_test,predictions_sign_with_bias_lr_0_1):.3f}') # Perceptron Sign With Bias LR 0.1\n",
    "print(f'Precision Sign without bias LR 0.1 : {precision_score(y_test,predictions_sign_without_bias_lr_0_0_1):.3f}') # Perceptron Sign Without Bias LR 0.01\n",
    "print(f'Precision Sign without bias LR 0.1 : {precision_score(y_test,predictions_sign_with_bias_lr_0_0_1):.3f}') # Perceptron Sign With Bias LR 0.01\n",
    "print(f'Precision Sign without bias LR 0.1 : {precision_score((y_test+1)/2,perceptron_sklearn.predict(X_test_tensor.numpy())):.3f}')  #  Perceptron sklearn\n",
    "print(f'Precision SGD Optim LR 0.1 : {precision_score(y_test_tensor.numpy(), predicted_labels_sgd_lr_0_1.numpy()):.3f}')  # SGD Optim LR 0.1\n",
    "print(f'Precision SGD Optim LR 0.01 : {precision_score(y_test_tensor.numpy(), predicted_labels_sgd_lr_0_0_1.numpy()):.3f}')  # SGD Optim LR 0.01\n",
    "print(f'Precision Adam Optim LR 0.1 : {precision_score(y_test_tensor.numpy(), predicted_labels_adam_lr_0_1.numpy()):.3f}')  # Adam Optim LR 0.1\n",
    "print(f'Precision Adam Optim LR 0.01 : {precision_score(y_test_tensor.numpy(), predicted_labels_adam_lr_0_0_1.numpy()):.3f}')  # Adam Optim LR 0.01\n",
    "print(f'Precision RMSprop Optim LR 0.1 : {precision_score(y_test_tensor.numpy(), predicted_labels_rmsprop_lr_0_1.numpy()):.3f}')  # RMSprop Optim LR 0.1\n",
    "print(f'Precision RMSprop Optim LR 0.01 : {precision_score(y_test_tensor.numpy(), predicted_labels_rmsprop_lr_0_0_1.numpy()):.3f}')  # RMSprop Optim LR 0.01\n",
    "print(f'Precision Nadam Optim LR 0.1 : {precision_score(y_test_tensor.numpy(), predicted_labels_nadam_lr_0_1.numpy()):.3f}')  # Nadam Optim LR 0.1\n",
    "print(f'Precision Nadam Optim LR 0.01: {precision_score(y_test_tensor.numpy(), predicted_labels_nadam_lr_0_0_1.numpy()):.3f}')  # Nadam Optim LR 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e90c19-8a1c-4a11-b249-d9a6bbc62037",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Recall Sign without bias LR 0.1 : {recall_score(y_test,predictions_sign_without_bias_lr_0_1):.3f}') # Perceptron Sign Without Bias LR 0.1\n",
    "print(f'Recall Sign without bias LR 0.1 : {recall_score(y_test,predictions_sign_with_bias_lr_0_1):.3f}') # Perceptron Sign With Bias LR 0.1\n",
    "print(f'Recall Sign without bias LR 0.1 : {recall_score(y_test,predictions_sign_without_bias_lr_0_0_1):.3f}') # Perceptron Sign Without Bias LR 0.01\n",
    "print(f'Recall Sign without bias LR 0.1 : {recall_score(y_test,predictions_sign_with_bias_lr_0_0_1):.3f}') # Perceptron Sign With Bias LR 0.01\n",
    "print(f'Recall Sign without bias LR 0.1 : {recall_score((y_test+1)/2,perceptron_sklearn.predict(X_test_tensor.numpy())):.3f}')  #  Perceptron sklearn\n",
    "print(f'Recall SGD Optim LR 0.1 : {recall_score(y_test_tensor.numpy(), predicted_labels_sgd_lr_0_1.numpy()):.3f}')  # SGD Optim LR 0.1\n",
    "print(f'Recall SGD Optim LR 0.01 : {recall_score(y_test_tensor.numpy(), predicted_labels_sgd_lr_0_0_1.numpy()):.3f}')  # SGD Optim LR 0.01\n",
    "print(f'Recall Adam Optim LR 0.1 : {recall_score(y_test_tensor.numpy(), predicted_labels_adam_lr_0_1.numpy()):.3f}')  # Adam Optim LR 0.1\n",
    "print(f'Recall Adam Optim LR 0.01 : {recall_score(y_test_tensor.numpy(), predicted_labels_adam_lr_0_0_1.numpy()):.3f}')  # Adam Optim LR 0.01\n",
    "print(f'Recall RMSprop Optim LR 0.1 : {recall_score(y_test_tensor.numpy(), predicted_labels_rmsprop_lr_0_1.numpy()):.3f}')  # RMSprop Optim LR 0.1\n",
    "print(f'Recall RMSprop Optim LR 0.01 : {recall_score(y_test_tensor.numpy(), predicted_labels_rmsprop_lr_0_0_1.numpy()):.3f}')  # RMSprop Optim LR 0.01\n",
    "print(f'Recall Nadam Optim LR 0.1 : {recall_score(y_test_tensor.numpy(), predicted_labels_nadam_lr_0_1.numpy()):.3f}')  # Nadam Optim LR 0.1\n",
    "print(f'Recall Nadam Optim LR 0.01: {recall_score(y_test_tensor.numpy(), predicted_labels_nadam_lr_0_0_1.numpy()):.3f}')  # Nadam Optim LR 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02527fd0-05d2-4bf5-aeda-3406cef7981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision MLP Default : {precision_score(y_test_tensor.numpy(),mlp.predict(X_test_tensor.numpy())):.3f}')  # MLP default\n",
    "print(f'Precision MLP 300 100 : {precision_score(y_test_tensor.numpy(), mlp_300_100.predict(X_test_tensor.numpy())):.3f}')  # MLP 300 100\n",
    "print(f'Precision SVM : {precision_score(y_test_tensor.numpy(), svm_model.predict(X_test_tensor.numpy())):.3f}')  # SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0891b45-d7f1-4757-9c10-20f231f3095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Recall  MLP Default : {recall_score(y_test_tensor.numpy(),mlp.predict(X_test_tensor.numpy())):.3f}')  # MLP default\n",
    "print(f'Recall MLP 300 100 : {recall_score(y_test_tensor.numpy(), mlp_300_100.predict(X_test_tensor.numpy())):.3f}')  # MLP 300 100\n",
    "print(f'Recall SVM : {recall_score(y_test_tensor.numpy(), svm_model.predict(X_test_tensor.numpy())):.3f}')  # SVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
